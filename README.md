LangGraph Chatbot (Streamlit + SQLite + Gemini Tools)
ğŸš€ Overview

This project is a full chat application built using:

LangGraph for stateful conversation management

Google Gemini Flash models for generation

DuckDuckGo, Calculator, and Stock Price tools via LangChain

A local SQLite database for persistent threads

Streamlit as the frontend UI

Automatic chat titles using a secondary lightweight LLM (llm1)

It behaves like a mini ChatGPT with:

Multiple chat threads

Persistent conversation history

Tool usage visualization

Rename + delete chat

Real-time streaming responses

âœ¨ Features
âœ… Multi-Chat Thread System

Create unlimited chat threads

Automatically saved into SQLite

Load past conversations instantly

âœ… Gemini 2.5 Flash + Tools

Integrated tools:

DuckDuckGo Search

Calculator

Stock Price API

The system automatically decides when to call tools.

âœ… Persistent Chat Titles

First message â†’ auto-generated 5-word title

Titles stored locally (chat_titles.json)

Manually rename title via popup dialog

âœ… Clean & Modern UI (Streamlit)

Chat UI similar to ChatGPT

Rename popup dialog (Streamlit dialog)

Delete confirmation dialog

Tool status indicator (loading â†’ complete)

Message history displayed cleanly (tool messages filtered out)

âœ… Persistent Storage (SQLite)

Stores every message in LangGraph format

Uses SqliteSaver checkpointing

Thread-specific message isolation

ğŸ§© Architecture
1ï¸âƒ£ Frontend â€“ Streamlit

Responsible for:

User interface

Rendering chat messages

Thread list sidebar

Rename/Delete dialogs

Streaming assistant responses (token-by-token)

Sending queries to backend LangGraph

No business logic lives here â€” only UI and UX.

2ï¸âƒ£ Backend â€“ LangGraph + SQLite

The backend:

Manages stateful chatbot memory

Stores threads in SQLite

Runs all tool logic

Decides tool routing

Generates responses

Streams output progressively

Graph Structure:
START â†’ chat_node â†’ tools (conditional) â†’ chat_node â†’ END

Tools Integrated:

DuckDuckGo Search

Calculator

Stock Price API

Models Used:

llm (Gemini 2.5 Flash) â†’ Main chat model

llm1 (Gemini 2.0 Flash) â†’ For lightweight chat title generation

ğŸ“¦ Installation
1ï¸âƒ£ Clone the repository
git clone <your-repo-url>
cd <project-folder>

2ï¸âƒ£ Create virtual environment
python -m venv env
source env/bin/activate       # Mac/Linux
env\Scripts\activate          # Windows

3ï¸âƒ£ Install requirements
pip install -r requirements.txt

4ï¸âƒ£ Add .env
GEMINI_API_KEY=your_key
ALPHAVANTAGE_API_KEY=your_key

5ï¸âƒ£ Run the app
streamlit run frontend.py

ğŸ“ Folder Structure
project/
â”‚â”€â”€ backend_latest.py
â”‚â”€â”€ frontend.py
â”‚â”€â”€ chat_titles.json
â”‚â”€â”€ chatbot.db
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ .env
â”‚â”€â”€ README.md

ğŸ—‚ï¸ Database (SQLite)

Tables created by LangGraph:

checkpoints

writes

Each thread is uniquely identified by:

thread_id (UUID)


All messages for that thread are stored and restored automatically.

âš ï¸ Limitations

Even though the project works smoothly, here are the important limitations:

1ï¸âƒ£ Single-Machine Architecture (Not Cloud-Ready Yet)

SQLite is file-based. It cannot handle:

high concurrency

horizontal scaling

cloud-based multi-region access

For real production:
â¡ï¸ Replace SQLite with PostgreSQL or a scalable DB.

2ï¸âƒ£ Tool Messages Not Truly Hidden in Database

Although filtered in UI, tool call messages still exist internally in SQLite.

This is not a big issue but:

They are not rendered in UI

They do consume storage

3ï¸âƒ£ No User Authentication (Single User Only)

This system works for one user only.

If deployed publicly:

Anyone can see everyoneâ€™s chats

Sessions are not isolated

To support multi-user:
â¡ï¸ A proper backend (FastAPI) with JWT auth is required.

4ï¸âƒ£ No File Upload / RAG (Yet)

This project does not include RAG.

If a user uploads a file today:

There is no vector store

No document embeddings

Adding RAG requires:

A vector DB (FAISS, Chroma, PGVector)

Embedding model

Memory retention per thread

5ï¸âƒ£ Limited Gemini Free-Tier Rate Limits

Gemini Flash free-tier allows:

10 requests per minute

Tool-heavy prompts can quickly consume rate limits.

ChatTitle LLM (llm1) fixes most of this but:

Too many page reloads can still hit rate-limits

6ï¸âƒ£ Streamlit Is Not a Real Backend

Streamlit cannot handle:

Multi-user authentication

High traffic

Role-based permissions

It is ideal for demos, not production chat services.

ğŸš€ Future Improvements
1ï¸âƒ£ Add User Accounts (FastAPI + JWT)

To support users safely:

Build backend with FastAPI

Store users + threads in PostgreSQL

Streamlit frontend becomes UI only

2ï¸âƒ£ Add RAG (File Upload Support)

Let users upload PDFs, docs.

Needed:

Embedding model

Vector DB (FAISS, Chroma, PGVector)

Retrieve relevant chunks

Add to LangGraph state

3ï¸âƒ£ Replace SQLite With PostgreSQL

For real scaling:

Postgres

MySQL

Supabase

Neon.tech

Railway Postgres

4ï¸âƒ£ Add Cloud Deployment

Possible stacks:

Streamlit Cloud (UI)

FastAPI on Render / Railway (Backend)

Postgres on Neon (Database)

5ï¸âƒ£ Better Tool Handling

Show a small spinner in messages:

â€œFetching stock priceâ€¦â€

â€œSearching webâ€¦â€

ğŸ‰ Conclusion

Your project is now a fully working LangGraph-powered chatbot with:

âœ” Persistent threads
âœ” Streamlit UI
âœ” LangGraph state
âœ” SQLite backend
âœ” Gemini models
âœ” Tools
âœ” Auto titles
âœ” Renaming + deleting chats

It is an ideal portfolio project and can be expanded into a full SaaS app with a proper backend.
